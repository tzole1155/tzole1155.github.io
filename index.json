[{"authors":null,"categories":null,"content":"Computer vision researcher currently working at CERTH/ITI. I am particularly interested in multiple view geometry, deep learning and computer graphics and their employment for solving computer vision problems.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://tzole1155.github.io/author/georgios-albanis/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/georgios-albanis/","section":"authors","summary":"Computer vision researcher currently working at CERTH/ITI. I am particularly interested in multiple view geometry, deep learning and computer graphics and their employment for solving computer vision problems.","tags":null,"title":"Georgios Albanis","type":"authors"},{"authors":["Vlachopoulos Alexis","Georgiou Harris","Tzeletopoulou Aspasia","Kasnesis Panagiotis","Chatzigeorgiou Christos"," Kogias G. Dimitrios","Patrikakis Z. Charalampos","Albanis Georgios","Konstantoudakis Konstantinos","Dimou, Anastasios","Daras Petros"],"categories":null,"content":"","date":1606348800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1606348800,"objectID":"864c7f90662b8192b729d8fb049f3f2c","permalink":"https://tzole1155.github.io/publication/enabling_gesture/","publishdate":"2020-11-26T00:00:00Z","relpermalink":"/publication/enabling_gesture/","section":"publication","summary":"Search \u0026 Rescue (SAR) operations often require the full attention and movement-dedication of First Responders (FR) in specific high-priority tasks, other than controlling a device or generating a message. In this work, novel technologies of wearables for FRs and K9 units in SAR operations are presented. The first goal is to provide alternative and complementary, low-overhead means of messaging in highly-demanding environments. The second goal is to use such platforms as control apparatus that significantly lowers the workload for FRs when controlling complex equipment like robots. These technologies are currently under development and already prototyped as part of the SAR Kit of the FASTER project, which is to begin field testing activities this year.","tags":null,"title":"Enabling gesture-based controls for first responders and K9 units","type":"publication"},{"authors":["Yuan Honglin","Veltkamp C. Remco","Albanis Georgios","Zioulis Nikolaos","Zarpalas Dimitrios","Daras Petros"],"categories":null,"content":"","date":1598918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598918400,"objectID":"892211a6586755fa1709297e2950a077","permalink":"https://tzole1155.github.io/publication/shrec/","publishdate":"2020-09-01T00:00:00Z","relpermalink":"/publication/shrec/","section":"publication","summary":"6D pose estimation is crucial for augmented reality, virtual reality, robotic manipulation and visual navigation. However, the problem is challenging due to the variety of objects in the real world. They have varying 3D shape and their appearances in captured images are affected by sensor noise, changing lighting conditions and occlusions between objects. Different pose estimation methods have different strengths and weaknesses, depending on feature representations and scene contents. At the same time, existing 3D datasets that are used for data-driven methods to estimate 6D poses have limited view angles and low resolution. To address these issues, we organize the Shape Retrieval Challenge benchmark on 6D pose estimation and create a physically accurate simulator that is able to generate photo-realistic color-and-depth image pairs with corresponding ground truth 6D poses. From captured color and depth images, we use this simulator to generate a 3D dataset which has 400 photo-realistic synthesized color-and-depth image pairs with various view angles for training, and another 100 captured and synthetic images for testing. Five research groups register in this track and two of them submitted their results. Data-driven methods are the current trend in 6D object pose estimation and our evaluation results show that approaches which fully exploit the color and geometric features are more robust for 6D pose estimation of reflective and texture-less objects and occlusion. This benchmark and comparative evaluation results have the potential to further enrich and boost the research of 6D object pose estimation and its applications.","tags":null,"title":"SHREC 2020 track: 6D object pose estimation","type":"publication"},{"authors":["Albanis Georgios","Zioulis Nikolaos","Dimou Anastasios","Zarpalas Dimitrios","Daras Petros"],"categories":null,"content":"","date":1598140800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598140800,"objectID":"f0c46a9e8a31ed93d26b370e3891f1a7","permalink":"https://tzole1155.github.io/publication/dronepose/","publishdate":"2020-08-23T00:00:00Z","relpermalink":"/publication/dronepose/","section":"publication","summary":"In this work we consider UAVs as cooperative agents supporting human users in their operations. In this context, the 3D localisation of the UAV assistant is an important task that can facilitate the exchange of spatial information between the user and the UAV. To address this in a data-driven manner, we design a data synthesis pipeline to create a realistic multimodal dataset that includes both the exocentric user view, and the egocentric UAV view.","tags":null,"title":"DronePose: Photorealistic UAV-Assistant Dataset Synthesis for 3D Pose Estimation via a Smooth Silhouette Loss","type":"publication"},{"authors":["Konstantoudakis Konstantinos","Albanis Georgios","Christakis Emmanouil","Zioulis Nikolaos","Dimou, Anastasios","Zarpalas Dimitrios","Daras Petros"],"categories":null,"content":"","date":1590278400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590278400,"objectID":"ce215d6614dbc484a8612ba6280dcf01","permalink":"https://tzole1155.github.io/publication/singlehand/","publishdate":"2020-05-24T00:00:00Z","relpermalink":"/publication/singlehand/","section":"publication","summary":"Unmanned aerial vehicles (UAVs) have increased in popularity in recent years and are now involved in many activities, professional and otherwise. First responders, those teams and individuals who are the first to respond in crisis situations, have been using UAVs to assist them in locating victims and identifying hazards without endangering human personnel needlessly. However, professional UAV controllers tend to be heavy and cumbersome, requiring both hands to operate. First responders, on the other hand, often need to carry other important equipment and need to keep their hands free during a mission. This work considers enabling first responders to control UAVs with single-handed gestures, freeing their other hand and reducing their encumbrance. Two sets of gesture UAV controls are presented and implemented in a simulated environment, and a two-part user study is conducted: the first part assesses the comfort of each gesture and their intuitive association with basic flight control concepts; and the second evaluates two different modes of gesture control in a population of users including both genders, and first responders as well as members of the general populace. The results, consisting of both objective and subjective measurements, are discussed, hindrances and problems are identified, and directions of future work and research are mapped out.","tags":null,"title":"Single-handed gesture UAV control for first responders - a usability and performance user study","type":"publication"},{"authors":["Zikos Stylianos","Albanis Georgios","Tsourma Maria","Drosou Anastasios","Zarpalas Dimitrios","Daras Petros","Tzovaras Dimitrios"],"categories":null,"content":"","date":1569888000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569888000,"objectID":"5ff31b83882546a7037d1a51da5383af","permalink":"https://tzole1155.github.io/publication/humanfactory/","publishdate":"2019-10-01T00:00:00Z","relpermalink":"/publication/humanfactory/","section":"publication","summary":"With the advent of the fourth industrial revolution called Industry 4.0, the industrial world has shifted further towards automation, where advanced workplaces are replacing existing working stations. Moreover, human-machine collaboration has taken a big leap forward, placing human operators in the centre of attention. As such, this paper forms a review of the lessons learned from the point of view of five EU funded H2020 research projects (A4BLUE, Factory2Fit, INCLUSIVE, HUMAN and MANUWORK, 2016-2020), working in parallel and constituting the Human-Centred Factories (ACE Factories) cluster. Knowledge and technology providers, as well as industrial partners, have grouped together to deliver solutions that will bridge the gap to the factories of the future. The purpose of this white paper is to share the ACE Factories cluster understanding of future human-centred factories and to provide recommendations on how to get this vision into industrial practice. This is a key report of the ACE Factories cluster, which aims to support the replication of successful innovative technologies tested through the end-users of the ACE Factories cluster projects. The core target groups of this report are people in academia, industry practitioners and policy makers at the local, national and EU levels.","tags":null,"title":"Human-centered factories from theory to industrial practice. Lessons learned and recommendations.","type":"publication"},{"authors":["Tsourma Maria","Zikos Stylianos","Albanis Georgios","Konstantinos C Apostolakis","Evodoxia E Lithoxoidou","Anastastios Drosou","Zarpalas Dimitrios","Daras Petros","Tzovaras Dimitrios"],"categories":null,"content":"","date":1561939200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1561939200,"objectID":"e905e33b9c3e65330bc1460ab8c3fc01","permalink":"https://tzole1155.github.io/publication/gamification/","publishdate":"2019-07-01T00:00:00Z","relpermalink":"/publication/gamification/","section":"publication","summary":"This paper presents gamification concepts implemented by a gamification engine which is incorporated in a knowledge sharing web-based application. The engine aims at increasing user’s motivation and participation in knowledge sharing and training processes taking place on a factory’s shop floor, enhance socialization and support corrective feedback and positive reinforcement. In particular, it motivates workers to participate in discussions, propose solutions to work-related problems, and upload/view useful content even when being at the workplace. The gamification engine makes use of various gamification elements and is highly configurable in terms of management of gamified tasks. It is designed to support access by both standard display devices (PCs, tablets, mobile phones) as well as Mixed/Augmented Reality platforms, such as Microsoft HoloLens, which are gaining significant traction with industry verticals. The main novelty of the gamification concepts presented is the ability to utilize dynamic worker profile information which is stored in a central database, in order to improve the effectiveness of the gamified tasks, targeting at more effective usage of the knowledge sharing platform in the Industry 4.0 domain.","tags":null,"title":"Gamification concepts for leveraging knowledge sharing in Industry 4.0","type":"publication"},{"authors":["Albanis Georgios","Apostolakis C. Konstantinos","Öztürk Cemalettin","Zarpalas Dimitrios","Daras Petros"],"categories":null,"content":"","date":1536105600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1536105600,"objectID":"a360376cd5ebfbf8449c1e9766fd9c5d","permalink":"https://tzole1155.github.io/publication/adaptive/","publishdate":"2018-09-05T00:00:00Z","relpermalink":"/publication/adaptive/","section":"publication","summary":"The proliferation of IoT (Internet of Things) devices and networks along with the use of interactive user interfaces in the modern production environments, provide new opportunities for more effective assignment of tasks to resources. This paper proposes a novel integrated framework for offline task scheduling and resources assignment, which can be used in manufacturing industries. The proposed framework can be a part of an intelligent production system in an Industry 4.0 shop floor. For the creation of the work schedule referring to a time interval given a set of tasks and resources, such as workers and machines, multiple criteria are considered: execution restrictions, capabilities of resources, preferences, and past performance data. The main advantage of the scheduling framework is its potential to support adaptive and evolving decision-making based on feedback information received from various sources of the environment. Continuously updated data models that include the characteristics, requirements and performance metrics for each resource in a dynamic environment, as well as configuration settings and feedback provided by the manager, are taken into account in order to generate work schedules which can be efficient in terms of task-to-resource mapping and in accordance with manager’s preferences and policies. The implementation requirements of the proposed framework along with an initial system towards the implementation of the framework are also presented in this paper.","tags":null,"title":"Adaptive web-based tools for capability-driven workforce management and task sequencing optimization","type":"publication"}]